# ğŸš€ BigData Lab04 - Real-time Bitcoin ETL Pipeline

Dá»± Ã¡n nÃ y thá»±c hiá»‡n má»™t pipeline ETL (Extract-Transform-Load) hoÃ n chá»‰nh Ä‘á»ƒ phÃ¢n tÃ­ch streaming data vá» giÃ¡ Bitcoin (BTCUSDT) tá»« API Binance sá»­ dá»¥ng **Apache Kafka**, **Apache Spark**, vÃ  **MongoDB**.

## ğŸ¯ Tá»•ng quan

Pipeline bao gá»“m 3 giai Ä‘oáº¡n chÃ­nh:

1. **ğŸ“¥ Extract**: Thu tháº­p dá»¯ liá»‡u giÃ¡ Bitcoin tá»« Binance API vÃ  Ä‘áº©y vÃ o Kafka
2. **âš™ï¸ Transform**: Xá»­ lÃ½ dá»¯ liá»‡u vá»›i 2 phÆ°Æ¡ng phÃ¡p:
   - **Moving Statistics**: Thá»‘ng kÃª di Ä‘á»™ng (moving averages, standard deviation)
   - **Z-Score Analysis**: PhÃ¢n tÃ­ch Z-Score Ä‘á»ƒ phÃ¡t hiá»‡n anomaly
3. **ğŸ“¤ Load**: LÆ°u trá»¯ káº¿t quáº£ Ä‘Ã£ xá»­ lÃ½ vÃ o MongoDB

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Binance API   â”‚â”€â”€â”€â–¶â”‚     Extract     â”‚â”€â”€â”€â–¶â”‚   Kafka Topic   â”‚â”€â”€â”€â–¶â”‚   Transform     â”‚
â”‚   (BTC Price)   â”‚    â”‚   (Python)      â”‚    â”‚  'btc-price'    â”‚    â”‚   (PySpark)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚                       â”‚
                                                       â–¼                       â”‚
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
                                              â”‚   Bonus.py      â”‚               â”‚
                                              â”‚ (Window Analysis)â”‚               â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
                                                       â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚    MongoDB      â”‚â—€â”€â”€â”€â”‚      Load       â”‚â—€â”€â”€â”€â”‚   Kafka Topics  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚   (Results)     â”‚    â”‚   (Python)      â”‚    â”‚'btc-price-*'    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚'btc-price-higher'â”‚
                                              â”‚'btc-price-lower' â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ›  YÃªu cáº§u há»‡ thá»‘ng

- **Docker** vÃ  **Docker Compose** (v2.0+)
- **Ãt nháº¥t 4GB RAM** cho cÃ¡c container
- **Ãt nháº¥t 2GB disk space** cÃ²n trá»‘ng
- **Káº¿t ná»‘i internet** Ä‘á»ƒ download images vÃ  data tá»« Binance

## ğŸ“¦ CÃ i Ä‘áº·t vÃ  khá»Ÿi Ä‘á»™ng

### 1. Clone repository vÃ  chuáº©n bá»‹

```bash
git clone <repository-url>
cd BigData_Lab04

# Äáº£m báº£o cÃ¡c script cÃ³ quyá»n execute
chmod +x *.sh
```

### 2. Khá»Ÿi Ä‘á»™ng infrastructure

```bash
# Khá»Ÿi Ä‘á»™ng táº¥t cáº£ services (Kafka, MongoDB, Spark)
./start-docker.sh
```

Script nÃ y sáº½:
- âœ… Kiá»ƒm tra Docker vÃ  Docker Compose
- ğŸ”¨ Build Python application image
- ğŸš€ Khá»Ÿi Ä‘á»™ng Zookeeper, Kafka, MongoDB, Spark
- ğŸ“‹ Táº¡o Kafka topics cáº§n thiáº¿t
- â³ Äá»£i services sáºµn sÃ ng

### 3. Thiáº¿t láº­p MongoDB (tÃ¹y chá»n)

```bash
# Táº¡o collections vÃ  indexes cho MongoDB
./setup-mongodb.sh
```

### 4. Cháº¡y ETL Pipeline

```bash
# Menu tÆ°Æ¡ng tÃ¡c Ä‘á»ƒ chá»n component
./run-python-app.sh
```

## ğŸ® CÃ¡ch sá»­ dá»¥ng

### ğŸš€ Quick Start - Full Pipeline

1. Khá»Ÿi Ä‘á»™ng infrastructure:
   ```bash
   ./start-docker.sh
   ```

2. Cháº¡y Full ETL Pipeline:
   ```bash
   ./run-python-app.sh
   # Chá»n option 7: Full Pipeline
   ```

3. Theo dÃµi qua Web UI:
   - **Kafka UI**: http://localhost:8080
   - **Spark Master**: http://localhost:8081
   - **Spark Worker**: http://localhost:8082

### ğŸ“‹ Cháº¡y tá»«ng component riÃªng láº»

#### 1. Extract (Data Ingestion)
```bash
./run-python-app.sh
# Chá»n option 1: Extract
```
- Thu tháº­p giÃ¡ Bitcoin tá»« Binance API má»—i 100ms
- Gá»­i vÃ o Kafka topic `btc-price`
- Äá»‹nh dáº¡ng JSON vá»›i timestamp ISO8601

#### 2. Transform Moving Statistics
```bash
./run-python-app.sh  
# Chá»n option 2: Transform Moving Stats
```
- Äá»c tá»« topic `btc-price`
- TÃ­nh moving averages vÃ  standard deviations
- Multiple time windows: 30s, 1m, 5m, 15m, 30m, 1h
- Gá»­i káº¿t quáº£ vÃ o topic `btc-price-moving`

#### 3. Transform Z-Score Analysis
```bash
./run-python-app.sh
# Chá»n option 3: Transform Z-Score  
```
- PhÃ¡t hiá»‡n anomaly trong giÃ¡ Bitcoin
- TÃ­nh Z-score Ä‘á»ƒ identify outliers
- Gá»­i káº¿t quáº£ vÃ o topic `btc-price-zscore`

#### 4. Load (Data Storage)
```bash
./run-python-app.sh
# Chá»n option 4: Load
```
- LÆ°u dá»¯ liá»‡u tá»« Kafka vÃ o MongoDB
- Tá»± Ä‘á»™ng phÃ¢n chia theo time windows
- Collections: `btc-price-*-30s`, `btc-price-*-1m`, etc.

#### 5. Bonus Analysis (Shortest Windows)
```bash
./run-python-app.sh
# Chá»n option 5: Bonus
```
- PhÃ¢n tÃ­ch shortest windows cá»§a negative outcomes
- TÃ¬m thá»i gian Ä‘áº¿n giÃ¡ cao hÆ¡n/tháº¥p hÆ¡n trong window 20s
- Gá»­i káº¿t quáº£ vÃ o topics `btc-price-higher` vÃ  `btc-price-lower`
- Late data tolerance: 10 giÃ¢y

## ğŸ“Š Monitoring vÃ  Debug

### Web UI Interfaces

| Service | URL | MÃ´ táº£ |
|---------|-----|-------|
| Kafka UI | http://localhost:8083 | Quáº£n lÃ½ Kafka topics, messages |
| Spark Master | http://localhost:8081 | Spark cluster status |
| Spark Worker | http://localhost:8082 | Worker node status |

### Command Line Monitoring

```bash
# Xem messages trong Kafka topic
./run-python-app.sh
# Chá»n option 8: Monitor Topics

# Xem logs cá»§a services
docker compose logs -f kafka
docker compose logs -f spark-master
docker logs extract-service

# MongoDB shell
./run-python-app.sh  
# Chá»n option 9: MongoDB Shell

# Hoáº·c trá»±c tiáº¿p:
docker exec -it mongodb mongosh bigdata_lab04 -u admin -p password123
```

### Kiá»ƒm tra dá»¯ liá»‡u trong MongoDB

```javascript
// Xem moving statistics
db['btc-price-moving-1m'].find().limit(5).pretty()

// Xem z-score analysis  
db['btc-price-zscore-1m'].find().limit(5).pretty()

// Count documents
db['btc-price-moving-1m'].countDocuments()
```

## ğŸ”§ Cáº¥u trÃºc dá»± Ã¡n

```
BigData_Lab04/
â”œâ”€â”€ ğŸ“ src/                          # MÃ£ nguá»“n Python ETL
â”‚   â”œâ”€â”€ extract.py                   # Data ingestion tá»« Binance API
â”‚   â”œâ”€â”€ transform_moving_stats.py    # PySpark moving statistics
â”‚   â”œâ”€â”€ transform_zscore.py          # PySpark Z-score analysis  
â”‚   â”œâ”€â”€ load.py                      # Load data vÃ o MongoDB
â”‚   â””â”€â”€ bonus.py                     # Bonus: Trend analysis
â”œâ”€â”€ ğŸ“ docs/                         # TÃ i liá»‡u vÃ  bÃ¡o cÃ¡o
â”œâ”€â”€ ğŸ“ checkpoints/                  # Spark streaming checkpoints
â”œâ”€â”€ ğŸ³ Dockerfile                    # Python app container
â”œâ”€â”€ ğŸ³ docker-compose.yml            # Multi-service orchestration
â”œâ”€â”€ ğŸ“‹ requirements.txt              # Python dependencies  
â”œâ”€â”€ ğŸš€ start-docker.sh               # Khá»Ÿi Ä‘á»™ng infrastructure
â”œâ”€â”€ ğŸ run-python-app.sh             # Menu cháº¡y ETL components
â”œâ”€â”€ ğŸ›‘ stop-docker.sh                # Dá»«ng táº¥t cáº£ services
â”œâ”€â”€ ğŸ—„ï¸ setup-mongodb.sh              # Thiáº¿t láº­p MongoDB
â””â”€â”€ ğŸ“– README.md                     # File nÃ y
```

## âš™ï¸ Cáº¥u hÃ¬nh

### Environment Variables

| Variable | Default | MÃ´ táº£ |
|----------|---------|-------|
| `KAFKA_BOOTSTRAP_SERVERS` | `kafka:29092` | Kafka cluster endpoint |
| `MONGO_HOST` | `mongodb` | MongoDB hostname |
| `MONGO_PORT` | `27017` | MongoDB port |
| `MONGO_DB` | `bigdata_lab04` | Database name |
| `SPARK_MASTER` | `spark://spark-master:7077` | Spark cluster URL |

### Kafka Topics

| Topic | MÃ´ táº£ | Producer | Consumer |
|-------|-------|----------|----------|
| `btc-price` | Raw Bitcoin price data | extract.py | transform_*.py, bonus.py |
| `btc-price-moving` | Moving statistics results | transform_moving_stats.py | load.py |
| `btc-price-zscore` | Z-score analysis results | transform_zscore.py | load.py |
| `btc-price-higher` | Higher price windows (bonus) | bonus.py | load.py |
| `btc-price-lower` | Lower price windows (bonus) | bonus.py | load.py |

### MongoDB Collections

| Collection | MÃ´ táº£ | Time Window |
|------------|-------|-------------|
| `btc-price-moving-30s` | Moving stats 30 seconds | 30s |
| `btc-price-moving-1m` | Moving stats 1 minute | 1m |
| `btc-price-zscore-1m` | Z-score 1 minute | 1m |
| `btc-price-higher-windows` | Higher price windows (bonus) | Real-time |
| `btc-price-lower-windows` | Lower price windows (bonus) | Real-time |
| ... | ... | ... |

## ğŸ› Troubleshooting

### Váº¥n Ä‘á» thÆ°á»ng gáº·p

#### 1. Docker containers khÃ´ng khá»Ÿi Ä‘á»™ng
```bash
# Kiá»ƒm tra tráº¡ng thÃ¡i
docker compose ps

# Xem logs chi tiáº¿t
docker compose logs <service-name>

# Restart infrastructure
./stop-docker.sh
./start-docker.sh
```

#### 2. Kafka connection failed
```bash
# Kiá»ƒm tra Kafka health
docker compose exec kafka kafka-topics --list --bootstrap-server kafka:29092

# Test connectivity tá»« Python container
docker compose run --rm python-app python -c "
from kafka import KafkaProducer
producer = KafkaProducer(bootstrap_servers=['kafka:29092'])
print('âœ… Kafka connection OK')
"
```

#### 3. PySpark jobs failing
```bash
# Kiá»ƒm tra Spark Master UI
open http://localhost:8081

# Xem Spark logs
docker compose logs -f spark-master
docker compose logs -f spark-worker

# Test PySpark
docker compose run --rm python-app python -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('Test').getOrCreate()
print('âœ… PySpark OK')
"
```

#### 4. MongoDB connection issues
```bash
# Test MongoDB connection
docker compose exec mongodb mongosh --eval "db.adminCommand('ping')"

# Check MongoDB logs
docker compose logs -f mongodb
```

### Reset toÃ n bá»™

```bash
# Dá»«ng vÃ  xÃ³a táº¥t cáº£ data
./stop-docker.sh
# Chá»n option 2: XÃ³a volumes

# Khá»Ÿi Ä‘á»™ng láº¡i tá»« Ä‘áº§u
./start-docker.sh
./setup-mongodb.sh
```

## ğŸ“ˆ Performance Tuning

### Kafka Configuration
- TÄƒng `batch_size` trong producer Ä‘á»ƒ improve throughput
- Äiá»u chá»‰nh `linger_ms` Ä‘á»ƒ balance latency vs throughput

### Spark Configuration
- TÄƒng `spark.sql.shuffle.partitions` cho datasets lá»›n
- Äiá»u chá»‰nh `spark.driver.memory` vÃ  `spark.executor.memory`

### MongoDB Configuration
- Sá»­ dá»¥ng indexes phÃ¹ há»£p cho queries
- Xem xÃ©t sharding cho volume lá»›n

## ğŸš¦ Dá»«ng há»‡ thá»‘ng

```bash
# Dá»«ng táº¥t cáº£ services
./stop-docker.sh

# Options:
# 1. Giá»¯ dá»¯ liá»‡u (restart nhanh)
# 2. XÃ³a volumes (reset hoÃ n toÃ n) 
# 3. Dá»n dáº¹p Docker images
```

## ğŸ“š TÃ i liá»‡u tham kháº£o

- [Apache Kafka Documentation](https://kafka.apache.org/documentation/)
- [Apache Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [MongoDB Documentation](https://docs.mongodb.com/)
- [Binance API Documentation](https://binance-docs.github.io/apidocs/)

## ğŸ“ License

[MIT License](LICENSE)

---

**ğŸ‰ Happy Data Engineering!** 

Náº¿u gáº·p váº¥n Ä‘á», hÃ£y check logs vÃ  sá»­ dá»¥ng monitoring tools Ä‘á»ƒ debug.
